---
date: 2025-08-16T22:22:22Z
title: The de-Excellation of velut
draft: false
tags: ['Software', 'velut']
editHistory: [[2025-08-19, Link to completed plan]]
---

# The de-Excellation of velut

When I started my Latin dictionary (velut) in <time datetime="2016-02-05">February 2016</time>, it was an Excel file in its entirety.
<time datetime="2019-04-18 23:00">Three years later</time>, it was a much larger Excel file, but still nothing but an Excel file.
Now, it doesn’t use Excel at all.
The process of “de-Excellation” took me years, even after I made a detailed plan for how I would achieve it, but I’m so happy it’s done.

velut is now a website (made with Next.js), which reads from a MongoDB database.
The information for the database is generated by three JavaScript scripts, based off a Json file containing lemmata that I hand-edit.

This allows me to store much more information, and make changes much more quickly, than when the project was in Excel.

A [diagram of the new architecture](#diagram-of-architecture) is near the end of this article.
I also have an article showing [graphs of my progress](./graphs-of-lemma-and-word-counts).

## The Excel file

The Excel file has nine sheets, of which four are shown below.

- The `words` sheet stores data on Latin words as plaintext.
- The `wordsform` sheet generates the data for the `words` sheet based on the inputs in columns B and C. (These two columns are for the words themselves and the lemmata — dictionary headwords — that the words are inflected forms of.)
- The `lemmata` sheet stores data on Latin lemmata.
- The `output` sheet has an orange cell that serves as a search-bar, in that the sheet displays information (including rhymes and inflected forms) about whatever Latin word is typed in the orange cell.

<figure>
<img
	src="./images/2025/velut-excel-4sheets.png"
	alt="Composite screenshot of four Excel sheets"
	width="1000"
	style="aspect-ratio: 288 / 180;"
/>
<figcaption>Four of the sheets in the Excel file</figcaption>
</figure>

The other five sheets are as follows.

- The `multiword` sheet has a column for entering Latin words into, to the right of which are cells that say whether the words are in the `words` or `lemmata` sheets. Its online replacement is a page on the website called [Multi-word Look-up](https://www.velut.co.uk/multiword).
- The `decliner` sheet invents some of the inflected forms of whatever noun/adjective is typed into a certain cell.
- The `conjugator` sheet invents some of the inflected forms of whatever verb is typed into a certain cell.
- The `freqwhit` sheet contains some of the most <em>freq</em>uently used vocabulary in an open-source Latin dictionary program called <em>Whit</em>aker’s Words. This allows me to cross-reference words in velut and in Whitaker’s.
- The `misc` sheet holds several smaller tables, such as lists of metrical feet. It also has cells that perform some data-checks: eg “Do all the lemmata listed in the `words` sheet correspond to entries in the `lemmata` sheet?”

## The velut website

In <time datetime="2019-01-21">2019</time> I started learning software development formally, and created the velut website.
The site was itself part of the process of creating substitutes for functionality I had in Excel.
This is because I can use my Excel file to look up what data I have on a given word (in the `output` sheet), and the website allows anyone to see that information too.

The first time I could really say I had a “working” velut website was the <time datetime="2019-07-02">2nd of July, 2019</time>: for the first time you could enter a Latin word in the website’s search-bar and it would return the word from the MongoDB database, at least for me in development.
I deployed it <time datetime="2019-07-03">the next day</time>.

<time datetime="2019-07-08">Five days after that</time>, I had a job interview, in which I demoed the website.
I got the job and became a professional software developer.

Initially the website was in Create React App with a custom Express back-end.
I later re-wrote the site in Next.js, but that’s getting ahead of my narrative here.

## Generating Json

In my spare time, I continued to work on the website, add vocabulary to the Excel file, and refresh the website’s database with the new vocabulary.

You might ask, how did I convert Excel data into the Json format that the database needed?
Well, erm, I made another Excel file, and gave it formulae for generating Json strings from whatever was pasted into some cells.
This sort of worked, but was slow, and Excel was prone to crashing.
So (in <time datetime="2020-12-20">December 2020</time>) I made a webpage — my [Json Generator](https://www.duncanritchie.co.uk/velut-json-generator/) — where I could paste data in and download a Json file from that.
Much better.

Working with Excel was still very awkward.
But I had proven to myself that JavaScript could do things Excel could do, and could do them more efficiently.

## Declensions and conjugations

In <time datetime="2021-01-17">January 2021</time>, I created a [Decliner](https://www.duncanritchie.co.uk/velut-decliner) webpage to replace the Excel sheet that suggested inflected forms of nouns and adjectives.
This was <time datetime="2021-01-24">soon</time> followed by a [Conjugator](https://www.duncanritchie.co.uk/velut-conjugator) webpage to do the same for verbs.

These webpages were better than the Excel sheets they replaced, but not by much.
They allowed me to paste in some lemmata (including the part of speech in brackets after each lemma, if needed), and would make a primitive guess at what forms would be possible.
I could then copy the forms into Excel, taking care to edit forms manually that were not reasonable.

(I say primitive because a script cannot be expected to know the comparative and superlative forms simply from seeing <samp>bonus(adj)</samp>, for example.
Latin morphology is too complicated for everything to be inferable from just the lemma and part of speech.)

Going through the webpages every time I wanted to add nouns/adjectives/verbs to lemmata wasn’t very efficient for me.
And I would still have to correct the webpages’ mistakes, which were frequent.

I wasn’t thinking big enough.
I was still using Excel, and trying to make webpages that I could use alongside Excel.

## Moving the website to Next.js

Meanwhile, on the front-end of the website, I was using client-side–rendered [React.js](https://react.dev/), in the [Create React App](https://create-react-app.dev/) framework.
Visitors needed to have JavaScript enabled in their browser in order for the site to load.

This was okay — very few people disallow all JavaScript.
However, I felt it wasn’t quite how the web is supposed to work.
If a page is mostly informative, with few interactive elements beyond basic hyperlinks, why should the browser have to run a load of JavaScript?
Shouldn’t JavaScript be reserved for custom interactivity?

So I [migrated the velut website](./porting-velut-to-nextjs) from Create React App to Next.js, which supports server-side–rendering.
When a visitor requests a page, they receive a page, with all the content on it.
The browser still has to run some JavaScript to make things work the way Next.js wants them to work (technically this is called hydration), but you can disable JavaScript and the site continues to work perfectly fine.

And then the creators of Create React App deprecated Create React App.
Good thing I learnt Next.js and switched the website to the newer framework!

## Designing a new data architecture

<time datetime="2022-07-23">Having re-worked the front-end</time>, I turned my attention to the data.

The data were still being stored in Excel.
In a 90MB Excel file that took minutes to even open.
This was getting untenable.

So I made a plan for how to rid velut of Excel for good.
This was a Markdown document named `plan.md`, consisting of a check-list with many entries that I would complete sequentially (writing the date on each entry as I fulfilled it).
The zeroth step was to port the website to Next.js, which I had just done, of course.
The next step was to write the plan.
What was the plan to be?

Though I had been copying and pasting data into webpages (such as the Decliner, Conjugator, and Json Generator), this was a bit silly.
I needed something I could repeat and repeat, much more conveniently.
Therefore, I would write a lot more JavaScript, and run it outside of the browser, as Node.js scripts that I could invoke whenever I wanted.

I would have a Json file containing all the lemmata and whatever other information I might need about each lemma.
Then my scripts could use that to generate all the data that were to be programmatically generated — which would be saved as more Json files.
I would update the databases from there.
(And “databases” is plural here because, in writing the plan, I realised I needed to have a “development” database as well as the “production” one that the live website uses.
This might sound very odd, but the development instance of the site had been connecting to the production database.)

You can look in the Git history for [how the plan looked when I first wrote it](https://github.com/DuncanRitchie/velut/blob/7ff4ca03fde8e714e3ba9f296228b4c32dd09d07/plan.md) in <time datetime="2022-07-23">July 2022</time> and [how it looked when I was writing this article](https://github.com/DuncanRitchie/velut/blob/36d5eeb167d7e990a6dee8e0d138484a2239c2d4/plan.md) <time datetime="2025-07-20 21:01">three years later</time>.
<ins>Update: Here’s the [plan after it was completely fulfilled](https://github.com/DuncanRitchie/velut/blob/de30de8f402966d3bc4dff994fefca1bad77f0f9/plan.md).</ins>

## Generating `words` data

The `wordsform` sheet in Excel was used for producing certain data for each word, mostly phonetic data such as the metrical scansion or the location of the stressed syllable.
In <time datetime="2022-09-29">September 2022</time>, I made a JavaScript script to do this instead: my [Word Data Generator](https://www.duncanritchie.co.uk/velut-word-data-generator/).

One of the coolest things about JavaScript is that you can include it in webpages and browsers can run it against the webpage.
I quite liked being able to open the webpage for the Json Generator (for instance), put some data in the input field, and run the Json Generator from there.
Plus, I could include documentation on the webpage, which might be nicer to read than a readme file on GitHub.

So, before ensuring that the Word Data Generator ran in Node.js, I made a webpage for it and ensured it could run in the webpage.

To be fair, I also wanted to do it as a webpage because I didn’t have the list of words (the input data for the Word Data Generator) saved as a file in the correct format.
(Skip ahead to the [Lemmata Collator section](#the-lemmata-collator) for that bit.)

With the webpage made, I was able to paste a list of words (alongside the lemmata that the words were forms of) from Excel, generate all the word data, and replace the `words` collection (in the MongoDB database in production) with those generated data.
Aside from some bug-fixes, the generated data matched what I had produced in Excel.

## Collating forms from Excel

But where does the list of words come from?
It would come from scripts that were still to be made, such as my [Inflector](#the-inflector).

How does the Inflector know what lemmata to create inflected forms for?
I needed to export the information on the `lemmata` Excel sheet into a Json file on my computer.

How do I know the Inflector is generating all the words that I had had in Excel?
For every lemma, I needed the list of all the inflected forms that I had added to Excel.

So I <time datetime="2022-10-09">ran the Json Generator</time> on the `lemmata` data — the output became my source file of lemmata data — and <time datetime="2022-10-08">wrote</time> the [“Forms Collator”](https://www.duncanritchie.co.uk/velut-forms-collator/).
This takes a list of words with the lemmata that each word belongs to (which comprises two columns of the `words` sheet in Excel), and outputs a list of lemmata with the words that are forms of each lemma.

I saved this as a file, which looked like this:

```json
{
	"ā": ["ā", "āne"],
	"ab": ["ā", "ab", "āne", "abs", "absque"],
	"atque": ["ac", "atque"],
	"ad": ["ad"],
	"aes": ["aes", "aerēs", "aeris", "aerum", "aerī", "aeribus", "aerem", "aere"]
	// ...
}
```

<time datetime="2022-10-09">At this point</time>, I expected to never edit the Excel file again.
And I never did.

I now had:

- a Json file listing the lemmata that I had in Excel (with information such as their meanings and parts of speech), and
- a Json file listing the lemmata that I had in Excel (with their forms).

What I wanted was:

- a Json file listing lemmata, with information such as their meanings, parts of speech, and a complete set of forms.

## The Inflector

Let’s zoom out for a moment.

The “de-Excellation” of velut would bring many benefits to how I manage the dictionary behind the scenes.
But it also gave me the opportunity to improve how certain features appear on the website.
A major example is the list of forms for each lemma.

The tabular nature of Excel meant I couldn’t have the more complex data-structures that are useful for storing grammatical data about all the forms compactly.
In essence, I can use Excel to say that <a lang="la" href="https://www.velut.co.uk/verbi-">verbī</a> is a form of <a lang="la" href="https://www.velut.co.uk/verbum">verbum</a>, but it was very hard to store the information about it being genitive singular.

(It’s theoretically possible, but in practice implausible for the size of dictionary I was wanting.
I was prioritising number of lemmata and phonetic features such as rhymes, over grammatical information that’s already given by sites like Wiktionary and Perseus.)

So with data coming from Excel, velut presented the forms of <a lang="la" href="https://www.velut.co.uk/verbum">verbum</a> as a simple list: <a lang="la" href="https://www.velut.co.uk/verba">verba</a> <a lang="la" href="https://www.velut.co.uk/verbi-">verbī</a> <a lang="la" href="https://www.velut.co.uk/verbi-s">verbīs</a> <a lang="la" href="https://www.velut.co.uk/verbo-">verbō</a> <a lang="la" href="https://www.velut.co.uk/verbum">verbum</a>.
(I know <a lang="la" href="https://www.velut.co.uk/verbo-rum">verbōrum</a> is missing — I didn’t include every form.)
It couldn’t really be more informative.

And I was adding the forms manually, which has the advantage of not leading to the sorts of errors you get by generating forms through code.
If a lemma is irregular, it was easy for me to include the irregular forms.
If a lemma doesn’t make sense in the plural (or comparative, etc), I could easily avoid adding those forms.

But it also led to several mistakes due to human error — typos and errors in copying one cell to another — and it was difficult to correct them in Excel.
I also couldn’t include all the forms for all lemmata, nor the parsing information about each form, as I’ve said.
And adding the forms I did have was a bit tedious.

I did have some help in generating forms, first via the `decliner` and `conjugator` sheets in Excel, and then via the Decliner and Conjugator webpages, but still, it wasn’t great.

So this is where I was when, on the <time datetime="2022-10-09">9th of October 2022</time>, I exported all the data about lemmata and their forms from Excel into Json files.
<time datetime="2022-10-15">Then</time> I began to write a script to generate the forms from each lemma.
This script is the Inflector.

It includes all the grammatical information I want too, so it says what’s a genitive singular, etc.

Happily, as I’ve mentioned, I could use the data from Excel to check the forms that the Inflector generates (through the [Forms Collator](#collating-forms-from-excel)).
So if I had forms in Excel that the Inflector wasn’t re-creating, I knew about it.
I could then decide whether each form was a mistake and should never have been in velut, or it’s worth keeping.
In the latter case, either there was a bug in the Inflector, or the Json file that the Inflector reads from (listing all lemmata) needed more information about the lemma in question.

Working in Json means I can add custom fields to some lemmata in the data, and I can make the Inflector read them.
If a particular adjective has irregular stems for the comparative and superlative, for example, I can give that lemma object the fields `"ComparativeStems": ["meli"], "SuperlativeStems": ["optim"]"` and the Inflector would know that the resultant forms should be <i lang="la">melior melior melius, optimus optima optimum</i>, etc.

I could also include a field listing incorrect forms from Excel, so to avoid the warning that the Inflector wasn’t re-creating forms that had been in Excel.
The Inflector includes the incorrect forms in its output, but because they are marked as incorrect they are excluded from further processing.

<time datetime="2022-10-15">October 15th, 2022,</time> was when I put in the code checking the Inflector’s output against the forms from Excel.
On <time datetime="2022-10-15">the same day</time>, I made the Inflector generate “encliticized” forms, so practically any forms that are generated get replicated with <i lang="la" class="no-break">-ne</i>, <i lang="la" class="no-break">-que</i>, and <i lang="la" class="no-break">-ve</i> on the end.
(These are the three main enclitics of Latin, particles which can be attached to nearly any word in the language that doesn’t already have an enclitic.)

Also by the end of <time datetime="2022-10-15">October 15th</time>, all my tests for the expected forms were passing for conjunctions and prepositions.
Interjections followed soon after (<time datetime="2022-10-29">October 29th</time>).
These three parts of speech were the easiest because they mostly don’t have inflected forms except for the lemma form (plus the enclitics, for prepositions and some conjunctions — other conjunctions and interjections don’t even receive enclitics).

Eventually the Inflector was able to output all the forms that I had had in Excel (plus more) for every part of speech.
This was achieved for adverbs on <time datetime="2022-10-30">October 30th</time>, adjectives <time datetime="2022-11-13">November 13th</time>, pronouns <time datetime="2022-11-18">November 18th</time>, most non-proper nouns <time datetime="2022-12-10">December 10th</time>, proper nouns <time datetime="2022-12-30">December 30th</time>, verbs <time datetime="2023-04-30">April 30th (2023)</time>, and the remaining lemmata (third-declension i-stem nouns) <time datetime="2023-05-08">May 8th</time>.

As a sample of the output data, here’s part of the paradigm for a regular verb:

```json
{
	"unencliticized": {
		"indicative": {
			"active": {
				"present": {
					"singular": {
						"first": ["amō"],
						"second": ["amās"],
						"third": ["amat"]
					}
					// ...
				}
				// ...
			}
			// ...
		}
		// ...
	}
	// ...
}
```

The <time datetime="2023-05-20">Inflector combines this forms information</time> with the other details about lemmata from the source lemmata Json file.
(Or at least, it combines the forms with the lemmata details that the website reads.
Many lemmata only yield correct forms if the source file has certain extra information, such as oblique stems, but this does not need to be in the Inflector’s output.)
It also adds a couple more fields, such as the index number.

## Displaying forms on the website

Now all the objects of forms had been generated, my plan for de-Excellation said I needed to see what they looked like on the website.

To quote my article [“Good things happening to me in 2023”](./good-things-2023#velut):

> On the front-end of velut, I created a component for displaying inflected forms in nested `<dl>` elements (HTML description lists), and a “tabs” component that the description lists are displayed inside.
> This is keyboard-accessible, following [guidance from the Web Accessibility Initiative](https://www.w3.org/WAI/ARIA/apg/patterns/tabs/examples/tabs-automatic/) for the tabs, and is usable even if you don’t have JavaScript enabled in your browser.

Here’s a screenshot of <time datetime="2023-05-28">that</time>:

<figure>
<img alt="Declension chart (for Britannia, Britanniae) inside a tabs component" width="380" style="aspect-ratio: 570 / 644;" src="./images/2023/britannia-forms-without-background.webp" />
<figcaption>Generated forms for a proper noun</figcaption>
</figure>

This looks good, at least for lemmata that don’t have many forms or whose forms can be divided evenly by gender, number, case, etc.
It didn’t work so well for verbs.

To quote my article [“Good things happening to me in 2024”](./good-things-2024#velut):

> I also made two components specifically for displaying verb forms.
> One is for participles and the other is for non-participle forms.
> (I had a component for displaying any forms, which is used for other parts of speech, but it shows a lot of empty space when it’s used on verbs, because indicatives and imperatives etc have very different numbers of forms to each other.
> So I designed components that are more compact.)

And here’s a corresponding screenshot, for non-participle forms of a verb:

<figure>
	<img src="./images/2024/verb-table-amo-without-background_with-syncopated-forms.webp" alt="Table showing all single-word forms of amō except participles" width="1000" style="aspect-ratio: 1412 / 795; margin: 0.25rem; max-width: calc(100% - 0.5rem);" />
	<figcaption>Generated forms for a regular verb</figcaption>
</figure>

(If you’re wondering why some of the forms are different colours, it’s because I rendered forms as links if they were already in velut because they were in Excel.
Forms that were not in Excel are in black.
The screenshots above came from the pages for <a lang="la" href="https://www.velut.co.uk/Britannia">Britannia</a> and <a lang="la" href="https://www.velut.co.uk/amo-">amō</a>, so those specific forms are in grey.)

For more technical information, see my blogposts:

- [“`<col>` elements on verb tables”](./col-elements-on-verb-tables)
- [“Header-cells and `:hover` styles on my verb tables on velut”](./header-cells-on-verb-tables)

## Checking the Inflector’s output (part 1)

So by <time datetime="2023-05-08">May 2023</time>, my Inflector was outputting fairly sensible inflection information for all the lemmata I had.
I could see how those forms looked on the velut website (at least on my development instance — the forms tables weren’t on the live site yet, but the forms were in the development database that I <time datetime="2023-05-20">now</time> had).
But I wasn’t convinced it was all accurate.

You see, the data from Excel tell me what forms the Inflector misses (now none), but the Inflector could still have been creating forms that weren’t really reasonable for a given lemma, or the grammatical labels (genitive singular, etc) could have been wrong.
I knew I would have to manually go through all my lemmata and confirm that the forms information looked okay — either correcting the data when I noticed an error, or making a note to myself to do the emendation in the future.

I <time datetime="2023-05-28">configured</time> my development and production instances so that I could work on the inflected forms without them appearing on the live website before I had checked them.
And then I started checking all the forms.

<figure class="float-right">
<img alt="Screenshot of a webpage with text and progress bars referring to the writing and checking of the Inflector" width="450" style="aspect-ratio: 837 / 1080;" src="./images/2025/velut-deexcellation-page.webp" />
<figcaption>velut’s De-Excellation page</figcaption>
</figure>

## Updates on the website

At this point I realised that it would be nice to have a page on the velut website that showed my progress in checking the inflected forms (which are the output of the Inflector).
It would take a while for me to look over the forms for all lemmata.

<time datetime="2023-08-05">That page was live</time> at [www.velut.co.uk/deexcellation](https://www.velut.co.uk/deexcellation).

(Because the progress-bars are now at 100% and that’s not going to change, I will probably delete the page soon.)

The page also had a progress-bar for my work in writing the Inflector, somewhat pointlessly because I made the page after writing the Inflector, so the bar was always at 100%.
But it hopefully helped explain what I was doing with the Inflector and de-Excellation overall.

Moreover, the page also had an example of an inflection-table, a list of forms that I had decided to remove from velut, and much of the text in this article!

The Inflector ended with code to generate a “summary” Json file containing statistics (such as the number of lemmata I’d checked) and the list of incorrect forms.
The script I had to update my development database also updated the live database with this summary.
So the database contained three collections: `words`, `lemmata`, and `summary`.

Thus the de-Excellation webpage was kept up-to-date.

(Extra note: the summary file only ever contained the information from the most recent execution of the Inflector.
Perhaps I should have made it retain the statistics from previous executions.
As I say on my [graphs article](graphs-of-lemma-and-word-counts#progress-with-the-inflector:~:text=In%20hindsight%2C%20I%20could%20have%20made%20the%20Inflector%20append%20the%20statistics), one of the charts there would have been easier to draw if I had maintained such a file programmatically.)

## Checking the Inflector’s output (part 2)

Checking all the inflected forms took me about two years.
Throughout this, the de-Excellation webpage was being updated, and from time to time I published (to the live website) new batches of inflection-tables that had been checked.

More specifically, after I confirmed that all lemmata of a part of speech are given reasonable forms by the Inflector, I switched from showing a simple list of forms to displaying the full inflection-tables on the live website, for all lemmata of that part of speech.
(This was controlled through an <time datetime="2023-09-30">environment variable</time> that ensured only some tables were published, even if all were visible to me in development.)

However, because there were so many verbs to check, <time datetime="2024-10-18">I allowed the generated forms for any verb</time> that I had checked to be published, rather than waiting for all the verbs to have been checked.

The table below shows my progress in checking the inflected forms.

<details>
<summary>Table of dates when batches of lemmata had been checked</summary>

| Batch                               | Date of finishing checks                      |
| ----------------------------------- | --------------------------------------------- |
| Proper nouns                        | <time datetime="2023-09-16">2023-09-16</time> |
| Conjunctions                        | <time datetime="2023-09-17">2023-09-17</time> |
| Pronouns                            | <time datetime="2023-09-23">2023-09-23</time> |
| Nouns                               | <time datetime="2024-01-14">2024-01-14</time> |
| Prepositions                        | <time datetime="2024-01-27">2024-01-27</time> |
| Interjections                       | <time datetime="2024-01-28">2024-01-28</time> |
| Adverbs                             | <time datetime="2024-02-17">2024-02-17</time> |
| Third-declension adjectives         | <time datetime="2024-04-12">2024-04-12</time> |
| Other adjectives                    | <time datetime="2024-07-20">2024-07-20</time> |
| Deponent 1st-conjugation verbs      | <time datetime="2024-10-17">2024-10-17</time> |
| Deponent 2nd-conjugation verbs      | <time datetime="2024-10-20">2024-10-20</time> |
| Other deponent verbs                | <time datetime="2024-10-27">2024-10-27</time> |
| Semi-deponent verbs                 | <time datetime="2024-11-03">2024-11-03</time> |
| Non-deponent 1st-conjugation verbs  | <time datetime="2025-01-22">2025-01-22</time> |
| Non-deponent 2nd-conjugation verbs  | <time datetime="2025-02-15">2025-02-15</time> |
| Non-deponent 3rd-conjugation verbs  | <time datetime="2025-04-30">2025-04-30</time> |
| Non-deponent 4th-conjugation verbs  | <time datetime="2025-05-14">2025-05-14</time> |
| All other lemmata (irregular verbs) | <time datetime="2025-05-31">2025-05-31</time> |

</details>

For a more numbers-based view of my progress, see the [graph on my other article](./graphs-of-lemma-and-word-counts#progress-with-the-inflector).
I set myself targets for completing the Inflector in 2025, which that article explains too.

Eventually, by <time datetime="2025-05-31">the end of May 2025</time>, I had checked all lemmata and published their inflection-tables to the live website.

## Ambiguously stressed forms

Although I had checked all forms, there was one change I wanted to make to the Inflector’s output before moving on.

When the Inflector generated the inflected forms for a lemma, it didn’t consider any other lemmata.
It just looked at each lemma in isolation.
This is fine, for 99.997% of words.

However, velut is a rhyming dictionary — it can give you rhymes for the words you search for.
It’s probably the most comprehensive rhyming dictionary for Latin in existence.
And to know what words rhyme, velut needs to know how words are stressed.

There are words in Latin that are spelt the same, and macronized the same (with the same pattern of long and short vowels), but which have stress on different syllables.

For example, <i lang="la">[dominus](https://www.velut.co.uk/dominus)</i> “lord” and <i lang="la">[dominium](https://www.velut.co.uk/dominium)</i> “banquet” both have a genitive singular <i lang="la">[dominī](https://www.velut.co.uk/domini-)</i>, stressed on the first syllable for “of the lord” and on the second for “of the banquet”.
In velut, I differentiate between the two by putting an acute accent on <i lang="la">[domínī](https://www.velut.co.uk/domi.ni-)</i> “of the banquet”.

(I don’t put the acute on words that don’t need it due to not matching a word with a different stress.
Eg, words like <i lang="la">[imperī](https://www.velut.co.uk/imperi-)</i> — genitive singular of <i lang="la">[imperium](https://www.velut.co.uk/imperium)</i> — have the stress on penultimate syllable just like <i lang="la">domínī</i>, but there’s no other way of stressing <i lang="la">imperī</i>, so I forgo the accent.)

When the words data were in Excel, I applied the acute accent manually… if I noticed that forms could coincide like this.
I wanted to have an automated solution.

On June 1st, 2025, I implemented this “programmatic handling of ambiguously stressed forms”.
(I had added it to the plan for de-Excellation in <time datetime="2022-12-18 22:24">December 2022</time>.)
After the Inflector generates all forms, it scans through them all, looking for ones that might need to be disambiguated and recording their locations in the data.
Then it adds the acute accents where they are needed.

As a general rule, for Latin words of three or more syllables, the penultimate syllable (the penult) is stressed if it is long, and the antepenult is stressed if the penult is short.
The disambiguation I’m talking about here applies only to words with a short penult.

Why would a short penult be stressed?

- The word is a contraction ending in <span class="no-break">-ī</span> of a genitive singular ending in <span class="no-break">-iī</span>, such as <i lang="la">domínī</i> from <i lang="la">dominiī</i> (“of the banquet”, not “of the lord”).
- The word is a contraction ending in <span class="no-break">-iī</span> of a perfect-tense verb ending in <span class="no-break">-īvī</span>, such as <i lang="la">nescíī</i> from <i lang="la">nescīvī</i> (“I did not know”, not as a form of the adjective <i lang="la">nescius</i> “ignorant”).
- The word ends in an enclitic, such as <i lang="la">utráque</i> from <i lang="la">utra</i> (“and either of two”, not as a form of <i lang="la">uterque</i> “each of two”).

(The last of those rules is the most controversial.
I stress all encliticized words on the penult, but there’s not a lot of evidence supporting or rebutting this.
Some people, such as [Professor Charles Bennett](https://www.thelatinlibrary.com/bennett.html#sect6), would even say that my <i lang="la">utráque</i> should be <i lang="la">utraque</i> and my <i lang="la">utraque</i> should be <i lang="la">utráque</i>, and likewise for <i lang="la">plēréque</i>/<i lang="la">plēreque</i>!)

Below are the 53 pairs of forms that the Inflector currently adds an acute accent to disambiguate the stress on.

<details>
<summary>Minimal pairs for stress disambiguation</summary>

| Antepenult stress           | Penult stress               | Reason for penult stress                    |
| --------------------------- | --------------------------- | ------------------------------------------- |
| <i lang="la">cōnfugī</i>    | <i lang="la">cōnfúgī</i>    | Contraction of <i lang="la">cōnfugiī</i>    |
| <i lang="la">coniugī</i>    | <i lang="la">coniúgī</i>    | Contraction of <i lang="la">coniugiī</i>    |
| <i lang="la">diffugī</i>    | <i lang="la">diffúgī</i>    | Contraction of <i lang="la">diffugiī</i>    |
| <i lang="la">dominī</i>     | <i lang="la">domínī</i>     | Contraction of <i lang="la">dominiī</i>     |
| <i lang="la">effugī</i>     | <i lang="la">effúgī</i>     | Contraction of <i lang="la">effugiī</i>     |
| <i lang="la">indicī</i>     | <i lang="la">indícī</i>     | Contraction of <i lang="la">indiciī</i>     |
| <i lang="la">initī</i>      | <i lang="la">inítī</i>      | Contraction of <i lang="la">initiī</i>      |
| <i lang="la">itaque</i>     | <i lang="la">itáque</i>     | <i lang="la">ita</i> + enclitic             |
| <i lang="la">iūdicī</i>     | <i lang="la">iūdícī</i>     | Contraction of <i lang="la">iūdiciī</i>     |
| <i lang="la">nesciī</i>     | <i lang="la">nescíī</i>     | Contraction of <i lang="la">nescīvī</i>     |
| <i lang="la">obsequī</i>    | <i lang="la">obséquī</i>    | Contraction of <i lang="la">obsequiī</i>    |
| <i lang="la">perfugī</i>    | <i lang="la">perfúgī</i>    | Contraction of <i lang="la">perfugiī</i>    |
| <i lang="la">plēreque</i>   | <i lang="la">plēréque</i>   | <i lang="la">plēre</i> + enclitic           |
| <i lang="la">prīncipī</i>   | <i lang="la">prīncípī</i>   | Contraction of <i lang="la">prīncipiī</i>   |
| <i lang="la">prōdigī</i>    | <i lang="la">prōdígī</i>    | Contraction of <i lang="la">prōdigiī</i>    |
| <i lang="la">refugī</i>     | <i lang="la">refúgī</i>     | Contraction of <i lang="la">refugiī</i>     |
| <i lang="la">rēmigī</i>     | <i lang="la">rēmígī</i>     | Contraction of <i lang="la">rēmigiī</i>     |
| <i lang="la">subterfugī</i> | <i lang="la">subterfúgī</i> | Contraction of <i lang="la">subterfugiī</i> |
| <i lang="la">suffugī</i>    | <i lang="la">suffúgī</i>    | Contraction of <i lang="la">suffugiī</i>    |
| <i lang="la">utique</i>     | <i lang="la">utíque</i>     | <i lang="la">uti</i> + enclitic             |
| <i lang="la">utraque</i>    | <i lang="la">utráque</i>    | <i lang="la">utra</i> + enclitic            |
| <i lang="la">vulturī</i>    | <i lang="la">vultúrī</i>    | Contraction of <i lang="la">vulturiī</i>    |
| <i lang="la">augurī</i>     | <i lang="la">augúrī</i>     | Contraction of <i lang="la">auguriī</i>     |
| <i lang="la">exsilī</i>     | <i lang="la">exsílī</i>     | Contraction of <i lang="la">exsiliī</i>     |
| <i lang="la">beneficī</i>   | <i lang="la">benefícī</i>   | Contraction of <i lang="la">beneficiī</i>   |
| <i lang="la">officī</i>     | <i lang="la">offícī</i>     | Contraction of <i lang="la">officiī</i>     |
| <i lang="la">praesidī</i>   | <i lang="la">praesídī</i>   | Contraction of <i lang="la">praesidiī</i>   |
| <i lang="la">artificī</i>   | <i lang="la">artifícī</i>   | Contraction of <i lang="la">artificiī</i>   |
| <i lang="la">supplicī</i>   | <i lang="la">supplícī</i>   | Contraction of <i lang="la">suppliciī</i>   |
| <i lang="la">obsidī</i>     | <i lang="la">obsídī</i>     | Contraction of <i lang="la">obsidiī</i>     |
| <i lang="la">maleficī</i>   | <i lang="la">malefícī</i>   | Contraction of <i lang="la">maleficiī</i>   |
| <i lang="la">Tiberī</i>     | <i lang="la">Tibérī</i>     | Contraction of <i lang="la">Tiberiī</i>     |
| <i lang="la">aucupī</i>     | <i lang="la">aucúpī</i>     | Contraction of <i lang="la">aucupiī</i>     |
| <i lang="la">flāminī</i>    | <i lang="la">flāmínī</i>    | Contraction of <i lang="la">flāminiī</i>    |
| <i lang="la">fastīdiī</i>   | <i lang="la">fastīdíī</i>   | Contraction of <i lang="la">fastīdīvī</i>   |
| <i lang="la">arbitrī</i>    | <i lang="la">arbítrī</i>    | Contraction of <i lang="la">arbitriī</i>    |
| <i lang="la">haruspicī</i>  | <i lang="la">haruspícī</i>  | Contraction of <i lang="la">haruspiciī</i>  |
| <i lang="la">adulterī</i>   | <i lang="la">adultérī</i>   | Contraction of <i lang="la">adulteriī</i>   |
| <i lang="la">auspicī</i>    | <i lang="la">auspícī</i>    | Contraction of <i lang="la">auspiciī</i>    |
| <i lang="la">Aufidī</i>     | <i lang="la">Aufídī</i>     | Contraction of <i lang="la">Aufidiī</i>     |
| <i lang="la">colloquī</i>   | <i lang="la">collóquī</i>   | Contraction of <i lang="la">colloquiī</i>   |
| <i lang="la">exercitī</i>   | <i lang="la">exercítī</i>   | Contraction of <i lang="la">exercitiī</i>   |
| <i lang="la">exitī</i>      | <i lang="la">exítī</i>      | Contraction of <i lang="la">exitiī</i>      |
| <i lang="la">Herculī</i>    | <i lang="la">Hercúlī</i>    | Contraction of <i lang="la">Herculiī</i>    |
| <i lang="la">Rhodane</i>    | <i lang="la">Rhodáne</i>    | <i lang="la">Rhoda</i> + enclitic           |
| <i lang="la">martyrī</i>    | <i lang="la">martýrī</i>    | Contraction of <i lang="la">martyriī</i>    |
| <i lang="la">mūnicipī</i>   | <i lang="la">mūnicípī</i>   | Contraction of <i lang="la">mūnicipiī</i>   |
| <i lang="la">venēficī</i>   | <i lang="la">venēfícī</i>   | Contraction of <i lang="la">venēficiī</i>   |
| <i lang="la">Palladī</i>    | <i lang="la">Palládī</i>    | Contraction of <i lang="la">Palladiī</i>    |
| <i lang="la">comitī</i>     | <i lang="la">comítī</i>     | Contraction of <i lang="la">comitiī</i>     |
| <i lang="la">hospitī</i>    | <i lang="la">hospítī</i>    | Contraction of <i lang="la">hospitiī</i>    |
| <i lang="la">Ausonī</i>     | <i lang="la">Ausónī</i>     | Contraction of <i lang="la">Ausoniī</i>     |
| <i lang="la">interstitī</i> | <i lang="la">interstítī</i> | Contraction of <i lang="la">interstitiī</i> |

There’s also <i lang="la">nostrās</i>, which can be stressed on the penult or the ultima (the final syllable), but this is handled separately.

</details>

I <time datetime="2025-06-22">then</time> did a bit of refactoring in the Inflector generally, just to make my code a bit neater.
Doing everything in one five-thousand-line JavaScript file isn’t exactly great for human readability.

## The Lemmata Collator

Next I needed a script to convert the output of the Inflector into the input for the Word Data Generator.
This is the [Lemmata Collator](https://www.duncanritchie.co.uk/velut-lemmata-collator).

It was so easy to do, I actually did it in <time datetime="2023-08-27">August 2023</time> as a proof of concept while making the Word Data Generator.
But I tidied it up a bit in <time datetime="2025-06-23">June 2025</time>, and made sure it worked with the actual output of the Inflector.

<time datetime="2025-07-05">Then</time> I made a performance enhancement in the Word Data Generator that related to encliticized words (ending in <i lang="la" class="no-break">-ne</i>, <i lang="la" class="no-break">-que</i>, or <i lang="la" class="no-break">-ve</i>).
Instead of the WDG trying to work out whether a word was encliticized, I decided that it would be more elegant to pass this information in from the Lemmata Collator, since it’s in the forms data from the Inflector.

So the Lemmata Collator receives the output of the Inflector, which is a list of lemmata including the inflected forms for each lemma.
Here’s one lemma from the Inflector:

```json
{
	"Index": 1,
	"Lemma": "ab",
	"PartOfSpeech": "Preposition",
	"Meanings": "from; by; since",
	"Notes": "‘ā’ usually before a consonant; ‘ab’ usually before a vowel; ‘ā’ or ‘abs’ before the letter t",
	"Transliterations": null,
	"Root": "ab",
	"NoMacra": "ab",
	"NoMacraLowerCase": "ab",
	"Forms": {
		"unencliticized": ["ā", "ab", "abs"],
		"ne": ["āne"],
		"que": ["āque", "absque"],
		"ve": ["āve"]
	}
}
```

The Lemmata Collator’s output (and the Word Data Generator’s input) is a list of words, including the lemmata that each word came from, and specifying the enclitic (if there’s an enclitic).

(The columns are actually separated by tab characters, not several spaces, but it’s easier to read here with the spaces.)

```txt
ā       ā ab       unencliticized
ab      ab         unencliticized
abs     ab         unencliticized
āne     ānus ab ā  ne
āque    ab ā       que
absque  absque ab  que
āve     ab ā       ve
```

(Note that <i lang="la">ā</i>, <i lang="la">absque</i>, <i lang="la">āne</i>, <i lang="la">āque</i>, and <i lang="la">āve</i> are not just forms of the preposition <i lang="la">ab</i>, but are also forms of the letter name <i lang="la">ā</i>, the anatomical noun <i lang="la">ānus</i>, and the post-classical preposition <i lang="la">absque</i>.
The grouping of lemmata with the forms here is why the script is called the Lemmata Collator.)

## Running the scripts together

It was finally time to run the Word Data Generator on the output of the Lemmata Collator!
The Word Data Generator had been ready since the <time datetime="2022-09-29">29th of September, 2022</time>, but now was the <time datetime="2025-06-23">23rd of June, 2025</time>, and I had 2,099,608 words coming from the Inflector via the Lemmata Collator.

And the Word Data Generator took two hours, 17 minutes, and 8.925 seconds to process all the words; then 5.049 seconds to concatenate the output into one file that I could upload to the database.
Oh dear.

But I’ve already mentioned finding a [performance improvement](#the-lemmata-collator:~:text=I%20made%20a%20performance%20enhancement), and when I did that (on <time datetime="2025-07-05">July 5th</time>) the processing time went down to 25 minutes, zero seconds (plus the five seconds for concatenation).

So that was pretty nice.
I could probably find further improvements, but this will do for now.

### Putting all the words into production

I <time datetime="2025-06-23">updated my local `words` collection</time> with the output of the Word Data Generator, and checked the website looked alright with more than two million words.

I found I needed pagination on lists of rhymes, which I really could have implemented six years earlier.
It’s been a “to-do” for a while!
But <time datetime="2025-07-02">once that was done</time>, I didn’t really have other changes to make to the front-end.

I updated the production database with a new `lemmata` collection (from the Inflector) and `words` collection (from the Word Data Generator) on the <time datetime="2025-07-05">5th of July, 2025</time>.
There were now 2,099,608 words on the live website.
(And you can [see that as a graph](./graphs-of-lemma-and-word-counts#words-on-the-live-website).)

This necessitated upgrading my MongoDB Atlas instance from the free tier to the cheapest paid tier.
As much as I like getting things for free, I think I have to concede that a 1.44-gigabyte database probably should cost me a little bit, especially as I’ve already been using the Atlas database for six years without paying.

### The Data Updater

<time datetime="2025-07-10">Now</time> I had some JavaScript scripts (the Inflector, Lemmata Collator, and Word Data Generator) and a Batch script to update the development/production database.
I adapted the latter to call the JavaScript scripts in the correct order, renamed it to the “velut Data Updater”, and put each step in the Data Updater behind a “Do you want to run this step?” question.

Thus I could update velut simply by editing the source lemmata Json file and then running the Data Updater.
I can check the output of each step before proceeding with the next step, and I can skip any steps I don’t want to run.

<details>
<summary>The velut Data Updater</summary>

```batch
@echo off

echo Welcome to Duncan's Data Updater for velut!


:: RUN SCRIPTS THAT GENERATE JSON

:ASK_RUN_INFLECTOR
echo:
set /P INPUT_RUN_INFLECTOR=Do you want to run the Inflector? (y/n)
if %INPUT_RUN_INFLECTOR%==y goto RUN_INFLECTOR
if %INPUT_RUN_INFLECTOR%==n goto SKIP_RUN_INFLECTOR
goto ASK_RUN_INFLECTOR

:RUN_INFLECTOR
echo Running Inflector...
cd C:\Users\Duncan Ritchie\Documents\Code\velut\velut-inflector
node inflector.js
goto ASK_RUN_LEMMATA_COLLATOR

:SKIP_RUN_INFLECTOR
echo Skipped the execution of the Inflector.
goto ASK_RUN_LEMMATA_COLLATOR


:ASK_RUN_LEMMATA_COLLATOR
echo:
set /P INPUT_RUN_LEMMATA_COLLATOR=Do you want to run the Lemmata Collator? (y/n)
if %INPUT_RUN_LEMMATA_COLLATOR%==y goto RUN_LEMMATA_COLLATOR
if %INPUT_RUN_LEMMATA_COLLATOR%==n goto SKIP_RUN_LEMMATA_COLLATOR
goto ASK_RUN_LEMMATA_COLLATOR

:RUN_LEMMATA_COLLATOR
echo Running Lemmata Collator...
cd C:\Users\Duncan Ritchie\Documents\Code\velut\velut-lemmata-collator
node collator.js
goto ASK_RUN_WORD_DATA_GENERATOR

:SKIP_RUN_LEMMATA_COLLATOR
echo Skipped the execution of the Lemmata Collator.
goto ASK_RUN_WORD_DATA_GENERATOR


:ASK_RUN_WORD_DATA_GENERATOR
echo:
set /P INPUT_RUN_WORD_DATA_GENERATOR=Do you want to run the Word Data Generator? (y/n)
if %INPUT_RUN_WORD_DATA_GENERATOR%==y goto RUN_WORD_DATA_GENERATOR
if %INPUT_RUN_WORD_DATA_GENERATOR%==n goto SKIP_RUN_WORD_DATA_GENERATOR
goto ASK_RUN_WORD_DATA_GENERATOR

:RUN_WORD_DATA_GENERATOR
echo Running Word Data Generator...
cd C:\Users\Duncan Ritchie\Documents\Code\velut\velut-word-data-generator
node generator.js
goto MONGOIMPORT

:SKIP_RUN_WORD_DATA_GENERATOR
echo Skipped the execution of the Word Data Generator.
goto MONGOIMPORT


:MONGOIMPORT
cd C:\Program Files\MongoDB\Tools\100\bin



:: UPDATE DATABASE LOCALLY

:ASK_UPDATE_LEMMATA_COLLECTION_LOCALLY
echo:
set /P INPUT_UPDATE_LEMMATA_COLLECTION_LOCALLY=Do you want to update the lemmata collection locally? (y/n)
if %INPUT_UPDATE_LEMMATA_COLLECTION_LOCALLY%==y goto UPDATE_LEMMATA_COLLECTION_LOCALLY
if %INPUT_UPDATE_LEMMATA_COLLECTION_LOCALLY%==n goto SKIP_UPDATE_LEMMATA_COLLECTION_LOCALLY
goto ASK_UPDATE_LEMMATA_COLLECTION_LOCALLY

:UPDATE_LEMMATA_COLLECTION_LOCALLY
echo Updating lemmata collection locally...
cd C:\Program Files\MongoDB\Tools\100\bin
mongoimport --uri "mongodb://localhost:27017/velut-local?&w=majority" --collection lemmata_new --drop --file "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\Json\lemmata-with-words-from-inflector_mongo.json"
cd C:\Program Files\MongoDB\Server\6.0\bin
mongosh "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\RenamingCollections\rename-lemmata-collection-locally.js"
goto ASK_UPDATE_WORDS_COLLECTION_LOCALLY

:SKIP_UPDATE_LEMMATA_COLLECTION_LOCALLY
echo Skipped the update of the lemmata collection locally.
goto ASK_UPDATE_WORDS_COLLECTION_LOCALLY


:ASK_UPDATE_WORDS_COLLECTION_LOCALLY
echo:
set /P INPUT_UPDATE_WORDS_COLLECTION_LOCALLY=Do you want to update the words collection locally? (y/n)
if %INPUT_UPDATE_WORDS_COLLECTION_LOCALLY%==y goto UPDATE_WORDS_COLLECTION_LOCALLY
if %INPUT_UPDATE_WORDS_COLLECTION_LOCALLY%==n goto SKIP_UPDATE_WORDS_COLLECTION_LOCALLY
goto ASK_UPDATE_WORDS_COLLECTION_LOCALLY

:UPDATE_WORDS_COLLECTION_LOCALLY
echo Updating words collection locally...
cd C:\Program Files\MongoDB\Tools\100\bin
mongoimport --uri "mongodb://localhost:27017/velut-local?&w=majority" --collection words_new --drop --file "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\Json\words-from-generator_mongo.json"
cd C:\Program Files\MongoDB\Server\6.0\bin
mongosh "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\RenamingCollections\rename-words-collection-locally.js"
goto ASK_UPDATE_LEMMATA_COLLECTION_IN_PROD

:SKIP_UPDATE_WORDS_COLLECTION_LOCALLY
echo Skipped the update of the words collection locally.
goto ASK_UPDATE_LEMMATA_COLLECTION_IN_PROD



:: UPDATE DATABASE IN PRODUCTION

:ASK_UPDATE_LEMMATA_COLLECTION_IN_PROD
echo:
set /P INPUT_UPDATE_LEMMATA_COLLECTION_IN_PROD=Do you want to update the lemmata collection in production? (y/n)
if %INPUT_UPDATE_LEMMATA_COLLECTION_IN_PROD%==y goto UPDATE_LEMMATA_COLLECTION_IN_PROD
if %INPUT_UPDATE_LEMMATA_COLLECTION_IN_PROD%==n goto SKIP_UPDATE_LEMMATA_COLLECTION_IN_PROD
goto ASK_UPDATE_LEMMATA_COLLECTION_IN_PROD

:UPDATE_LEMMATA_COLLECTION_IN_PROD
echo Updating lemmata collection in production...
cd C:\Program Files\MongoDB\Tools\100\bin
mongoimport --uri "PRODUCTION_DATABASE_REDACTED" --collection lemmata_new --drop --file "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\Json\lemmata-with-words-from-inflector_mongo.json"
cd C:\Program Files\MongoDB\Server\6.0\bin
mongosh "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\RenamingCollections\rename-lemmata-collection-in-prod.js"
goto ASK_UPDATE_WORDS_COLLECTION_IN_PROD

:SKIP_UPDATE_LEMMATA_COLLECTION_IN_PROD
echo Skipped the update of the lemmata collection in production.
goto ASK_UPDATE_WORDS_COLLECTION_IN_PROD


:ASK_UPDATE_WORDS_COLLECTION_IN_PROD
echo:
set /P INPUT_UPDATE_WORDS_COLLECTION_IN_PROD=Do you want to update the words collection in production? (y/n)
if %INPUT_UPDATE_WORDS_COLLECTION_IN_PROD%==y goto UPDATE_WORDS_COLLECTION_IN_PROD
if %INPUT_UPDATE_WORDS_COLLECTION_IN_PROD%==n goto SKIP_UPDATE_WORDS_COLLECTION_IN_PROD
goto ASK_UPDATE_WORDS_COLLECTION_IN_PROD

:UPDATE_WORDS_COLLECTION_IN_PROD
echo Updating words collection in production...
cd C:\Program Files\MongoDB\Tools\100\bin
mongoimport --uri "PRODUCTION_DATABASE_REDACTED" --collection words_new --drop --file "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\Json\words-from-generator_mongo.json"
cd C:\Program Files\MongoDB\Server\6.0\bin
mongosh "C:\Users\Duncan Ritchie\Documents\Code\velut\velutSideAssets\RenamingCollections\rename-words-collection-in-prod.js"
goto END

:SKIP_UPDATE_WORDS_COLLECTION_IN_PROD
echo Skipped the update of the words collection in production.
goto END



:END
echo:
echo The velut Data Updater script is at an end.
pause

```

</details>

### Scripts for renaming collections

The Data Updater contains calls to run certain extra scripts in the MongoDB shell environment, for example `mongosh "C:\...\RenamingCollections\rename-lemmata-collection-locally.js"`.
Why do these extra scripts exist?
I use the mongoimport utility to import data into the database, but I don’t override the existing data at first, because importing data takes some time.
If someone visits the velut website while the data are being imported, I want them to see the site with the old data, rather than seeing no data (or clearly incomplete data).
So I import the data as a new collection, then use the extra scripts to switch the collections (and delete the old data) after mongoimport has finished.
This is all handled by the Data Updater, so it’s quite convenient.

Here’s one of the scripts; the others are the same except for the collection and/or database instance.

<details>
<summary>Script to rename the lemmata collection for my development instance</summary>

```js
// YOU WILL LOSE THE LEMMATA COLLECTION locally if you run this,
// unless you have run the script to generate a lemmata_new collection first!

console.log('Inside rename-lemmata-collection-locally.js!')
var db = connect('mongodb://localhost:27017/velut-local?&w=majority')
db.lemmata.renameCollection('lemmata_old')
db.lemmata_new.renameCollection('lemmata')
db.lemmata_old.drop()
quit()

console.log('Completed rename-lemmata-collection-locally.js!')
```

</details>

### Limerick

This came into my head while making the Batch script.

> Here’s three cheers for the Data Updater,<br/>
> since it runs the Inflector and later<br/>
> runs the Lemm’ta Collator<br/>
> and the Word Generator<br/>
> then updates all the database data!

Yes, I know it’s the Word <em>Data</em> Generator, but that broke the metre.

## Tidying up the new architecture

By <time datetime="2025-07-11">July 11th, 2025</time>, I was able to follow this workflow for adding vocabulary to velut:

1. adding a lemma (or several!) to the source Json file, and
2. running the Data Updater to propagate the changes through the JavaScript scripts and the generated Json files and into the database (for development and production).<br/>
   After each step in the Data Updater, I can check the effect, either by looking at the Git diff or by inspecting the website in a browser, depending on what the step was.

The next step on my plan was to open up the velut Excel file and ensure everything in it also exists outside of it.
(I did this on <time datetime="2025-07-13">July 13th</time>.)
There was one table of data that I needed to copy to a Json file (via the [Json Generator](#generating-json), of course).
This was the `freqwhit` sheet, and it contained some vocabulary that is not yet in velut.
Eventually I will go through those words, but not yet!

Subsequently, my plan said I should evaluate whether I should discard the development database and switch back to using the production database in development.
<time datetime="2025-07-13">I decided to keep the development database.</time>
It means I’m not querying the production database when I don’t need to, I can update the website (in development) even if I lose internet connection, and I can see changes on the development instance while the production database is being updated (which can take a while).
So yeah, having a separate database instance for development is a good idea.

Then I realised I needed to make some additions to my plan, so that obsolete things could be deleted.
So the end of the plan became this:

<blockquote>
<ul class="checklist">
<li> ✅ At this point, there’s a <code>summary</code> MongoDB collection, which is used by the webpage that shows my progress with de-Excellation (/deexcellation). Make sure the website isn’t reading from this collection anywhere except on the /deexcellation page. (This step and some of the steps below were not in the original plan, but were added on 2025-07-20.) <ins>Done 2025-07-20.</ins></li>
<li> 🔳 Write a blog article about the de-Excellation of velut, adapted from this plan and the webpage for showing my progress. The article should include a diagram of the new architecture (see below), the code for the Batch script (without database credentials, of course), and an explanation that the <code>summary</code> collection was useful and now isn’t.</li>
<li> 🔳 Update the readme in this repo. It should have a link to the blog article, and no link to this plan or the /deexcellation page.</li>
<li> 🔳 Delete the /deexcellation page.</li>
<li> 🔳 Delete the <code>summary</code> collection, locally and in production.</li>
<li> ✅ Evaluate whether the Excel file can be deprecated. <ins>File evaluated as obsolete 2025-07-13. To be fair, it’s been pretty much obsolete since 2022-10-09.</ins></li>
<li> 🔳 Continue adding words and going through issues. (I have several private Trello boards, including several for velut.)</li>
</ul>

When all the steps above have been ticked and dated, I will delete this file (plan.md).

</blockquote>

So I’ve stopped my scripts generating/importing data for the `summary` MongoDB collection, and I’ve made sure I can delete the de-Excellation webpage and the `summary` collection without the rest of the website breaking.
(Nonetheless, I haven’t deleted the collection and webpage yet.)

And now you’re reading my blog article about de-Excellation.
I will have published it before completing the remaining steps on the plan for de-Excellation.
If I’ve deleted that plan, it means I’ve finished the de-Excellation!

<ins>Update: I have indeed finished the de-Excellation and deleted the plan.
Here’s [how the plan looked when it was all ticked off](https://github.com/DuncanRitchie/velut/blob/de30de8f402966d3bc4dff994fefca1bad77f0f9/plan.md).</ins>

## Diagram of architecture

<details>
<summary>Diagram</summary>

<figure>
<div class="mermaid">

<svg id="diagram" width="100%" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" class="flowchart" style="max-width: 976px;" viewBox="-40 -40 976 1294" aria-roledescription="flowchart-v2" aria-describedby="chart-desc-diagram" aria-labelledby="chart-title-diagram" preserveAspectRatio="xMinYMin"><title id="chart-title-diagram">New architecture of velut</title><desc id="chart-desc-diagram">Text equivalent in explanation above</desc><style>#diagram{font-family:inherit;font-size:inherit;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#diagram .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#diagram .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#diagram .error-icon{fill:#552222;}#diagram .error-text{fill:#552222;stroke:#552222;}#diagram .edge-thickness-normal{stroke-width:1px;}#diagram .edge-thickness-thick{stroke-width:3.5px;}#diagram .edge-pattern-solid{stroke-dasharray:0;}#diagram .edge-thickness-invisible{stroke-width:0;fill:none;}#diagram .edge-pattern-dashed{stroke-dasharray:3;}#diagram .edge-pattern-dotted{stroke-dasharray:2;}#diagram .marker{fill:#333333;stroke:#333333;}#diagram .marker.cross{stroke:#333333;}#diagram svg{font-family:inherit;font-size:inherit;}#diagram p{margin:0;}#diagram .label{font-family:inherit;color:#333;}#diagram .cluster-label text{fill:#333;}#diagram .cluster-label span{color:#333;}#diagram .cluster-label span p{background-color:transparent;}#diagram .label text,#diagram span{fill:#333;color:#333;}#diagram .node rect,#diagram .node circle,#diagram .node ellipse,#diagram .node polygon,#diagram .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#diagram .rough-node .label text,#diagram .node .label text,#diagram .image-shape .label,#diagram .icon-shape .label{text-anchor:middle;}#diagram .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#diagram .rough-node .label,#diagram .node .label,#diagram .image-shape .label,#diagram .icon-shape .label{text-align:center;}#diagram .node.clickable{cursor:pointer;}#diagram .root .anchor path{fill:#333333!important;stroke-width:0;stroke:#333333;}#diagram .arrowheadPath{fill:#333333;}#diagram .edgePath .path{stroke:#333333;stroke-width:2.0px;}#diagram .flowchart-link{stroke:#333333;fill:none;}#diagram .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#diagram .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#diagram .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#diagram .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#diagram .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#diagram .cluster text{fill:#333;}#diagram .cluster span{color:#333;}#diagram div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:inherit;font-size:inherit;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#diagram .flowchartTitleText{text-anchor:middle;font-size:inherit;fill:#333;}#diagram rect.text{fill:none;stroke-width:0;}#diagram .icon-shape,#diagram .image-shape{background-color:rgba(232,232,232, 0.8);text-align:center;}#diagram .icon-shape p,#diagram .image-shape p{background-color:rgba(232,232,232, 0.8);padding:2px;}#diagram .icon-shape rect,#diagram .image-shape rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#diagram .label-icon{display:inline-block;height:1em;overflow:visible;vertical-align:-0.125em;}#diagram .node .label-icon path{fill:currentColor;stroke:revert;stroke-width:revert;}#diagram :root{--mermaid-font-family:inherit;}</style><g><marker id="diagram_flowchart-v2-pointEnd" class="marker flowchart-v2" viewBox="0 0 10 10" refX="5" refY="5" markerUnits="userSpaceOnUse" markerWidth="8" markerHeight="8" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" class="arrowMarkerPath" style="stroke-width: 1px; stroke-dasharray: 1px, 0px;"></path></marker><marker id="diagram_flowchart-v2-pointStart" class="marker flowchart-v2" viewBox="0 0 10 10" refX="4.5" refY="5" markerUnits="userSpaceOnUse" markerWidth="8" markerHeight="8" orient="auto"><path d="M 0 5 L 10 10 L 10 0 z" class="arrowMarkerPath" style="stroke-width: 1px; stroke-dasharray: 1px, 0px;"></path></marker><marker id="diagram_flowchart-v2-circleEnd" class="marker flowchart-v2" viewBox="0 0 10 10" refX="11" refY="5" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><circle cx="5" cy="5" r="5" class="arrowMarkerPath" style="stroke-width: 1px; stroke-dasharray: 1px, 0px;"></circle></marker><marker id="diagram_flowchart-v2-circleStart" class="marker flowchart-v2" viewBox="0 0 10 10" refX="-1" refY="5" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><circle cx="5" cy="5" r="5" class="arrowMarkerPath" style="stroke-width: 1px; stroke-dasharray: 1px, 0px;"></circle></marker><marker id="diagram_flowchart-v2-crossEnd" class="marker cross flowchart-v2" viewBox="0 0 11 11" refX="12" refY="5.2" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><path d="M 1,1 l 9,9 M 10,1 l -9,9" class="arrowMarkerPath" style="stroke-width: 2px; stroke-dasharray: 1px, 0px;"></path></marker><marker id="diagram_flowchart-v2-crossStart" class="marker cross flowchart-v2" viewBox="0 0 11 11" refX="-1" refY="5.2" markerUnits="userSpaceOnUse" markerWidth="11" markerHeight="11" orient="auto"><path d="M 1,1 l 9,9 M 10,1 l -9,9" class="arrowMarkerPath" style="stroke-width: 2px; stroke-dasharray: 1px, 0px;"></path></marker><g class="root"><g class="clusters"></g><g class="edgePaths"><path d="M448,86L448,92.167C448,98.333,448,110.667,448,122.333C448,134,448,145,448,150.5L448,156" id="L_A_B_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M402.183,196.459L358.153,205.549C314.122,214.639,226.061,232.82,182.031,254.576C138,276.333,138,301.667,138,327C138,352.333,138,377.667,138,401C138,424.333,138,445.667,138,467C138,488.333,138,509.667,138,533C138,556.333,138,581.667,138,607C138,632.333,138,657.667,138,681C138,704.333,138,725.667,138,747C138,768.333,138,789.667,138,805.833C138,822,138,833,138,838.5L138,844" id="L_B_C_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M493.817,205.918L512.014,213.432C530.211,220.945,566.606,235.973,584.803,248.986C603,262,603,273,603,278.5L603,284" id="L_B_D_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M682.539,366L695.116,372.167C707.693,378.333,732.846,390.667,745.423,402.333C758,414,758,425,758,430.5L758,436" id="L_D_E_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M758,494L758,500.167C758,506.333,758,518.667,758,530.333C758,542,758,553,758,558.5L758,564" id="L_E_F_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M758,646L758,652.167C758,658.333,758,670.667,758,682.333C758,694,758,705,758,710.5L758,716" id="L_F_G_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M758,774L758,780.167C758,786.333,758,798.667,758,812.333C758,826,758,841,758,848.5L758,856" id="L_G_H_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M138,926L138,932.167C138,938.333,138,950.667,138,962.333C138,974,138,985,138,990.5L138,996" id="L_C_I_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M523.461,366L510.884,372.167C498.307,378.333,473.154,390.667,460.577,407.5C448,424.333,448,445.667,448,467C448,488.333,448,509.667,448,533C448,556.333,448,581.667,448,607C448,632.333,448,657.667,448,681C448,704.333,448,725.667,448,747C448,768.333,448,789.667,448,813C448,836.333,448,861.667,448,887C448,912.333,448,937.667,448,955.833C448,974,448,985,448,990.5L448,996" id="L_D_J_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M758,914L758,922.167C758,930.333,758,946.667,758,960.333C758,974,758,985,758,990.5L758,996" id="L_H_K_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M138,1078L138,1084.167C138,1090.333,138,1102.667,175.94,1116.666C213.88,1130.666,260,1146.331,290,1154.164L314,1161.997" id="L_I_L_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M448,1078L448,1084.167C448,1090.333,448,1102.667,448,1114.333C448,1126,448,1137,448,1142.5L448,1148" id="L_J_L_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path><path d="M758,1078L758,1084.167C758,1090.333,758,1102.667,720.06,1116.666C682.12,1130.666,640,1146.331,610,1154.164L583,1161.997" id="L_K_L_0" class="edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link" style="" marker-end="url(#diagram_flowchart-v2-pointEnd)"></path></g><g class="edgeLabels"><g class="edgeLabel" transform="translate(448, 123)"><g class="label" transform="translate(-34.875, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is read by</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(138, 531)"><g class="label" transform="translate(-35.21666717529297, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>generates</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(603, 251)"><g class="label" transform="translate(-35.21666717529297, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>generates</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(758, 403)"><g class="label" transform="translate(-34.875, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is read by</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(758, 531)"><g class="label" transform="translate(-35.21666717529297, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>generates</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(758, 683)"><g class="label" transform="translate(-34.875, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is read by</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(758, 811)"><g class="label" transform="translate(-35.21666717529297, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>generates</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(138, 963)"><g class="label" transform="translate(-57.25, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is imported into</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(448, 683)"><g class="label" transform="translate(-57.25, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is imported into</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(758, 963)"><g class="label" transform="translate(-57.25, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is imported into</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(138, 1115)"><g class="label" transform="translate(-34.875, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is read by</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(448, 1115)"><g class="label" transform="translate(-34.875, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is read by</p></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(758, 1115)"><g class="label" transform="translate(-34.875, -18)"><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml" class="labelBkg"><span class="edgeLabel"><p>is read by</p></span></div></foreignObject></g></g></g><g class="nodes"><g class="node default" id="flowchart-A-0" transform="translate(448, 47)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="file">Json of source lemmata data</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-B-1" transform="translate(448, 187)"><rect class="basic label-container" style="" rx="5" ry="5" x="-130" y="-27" width="260" height="54"></rect><g class="label" style="" transform="translate(-66, -18)"><rect></rect><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="scroll"><a href="#the-inflector">Inflector</a></p></span></div></foreignObject></g></g><g class="node default" id="flowchart-C-3" transform="translate(138, 887)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="file">Json summary of Inflector work</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-D-5" transform="translate(603, 327)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="file">Json array of lemmata with their forms</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-E-7" transform="translate(758, 467)"><rect class="basic label-container" style="" rx="5" ry="5" x="-130" y="-27" width="260" height="54"></rect><g class="label" style="" transform="translate(-109, -18)"><rect></rect><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="scroll"><a href="#the-lemmata-collator">Lemmata Collator</a></p></span></div></foreignObject></g></g><g class="node default" id="flowchart-F-9" transform="translate(758, 607)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="file">simple list of words with their lemmata & enclitic</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-G-11" transform="translate(758, 747)"><rect class="basic label-container" style="" rx="5" ry="5" x="-130" y="-27" width="260" height="54"></rect><g class="label" style="" transform="translate(-125, -18)"><rect></rect><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="scroll"><a href="#generating-words-data">Word Data Generator</a></p></span></div></foreignObject></g></g><g class="node default" id="flowchart-H-13" transform="translate(758, 887)"><rect class="basic label-container" style="" x="-130" y="-27" width="260" height="54"></rect><g class="label" style="" transform="translate(-134, -18)"><rect></rect><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="file">Json array of word data</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-I-15" transform="translate(138, 1039)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="database"><code>summary</code> MongoDB collection</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-J-17" transform="translate(448, 1039)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="database"><code>lemmata</code> MongoDB collection</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-K-19" transform="translate(758, 1039)"><rect class="basic label-container" style="" x="-130" y="-39" width="260" height="78"></rect><g class="label" style="" transform="translate(-130, -30)"><rect></rect><foreignObject width="260" height="66"><div style="display: table; white-space: break-spaces; line-height: 1.5; max-width: 260px; text-align: center; width: 260px;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="database"><code>words</code> MongoDB collection</p></span></div></foreignObject></g></g><g class="node default" id="flowchart-L-21" transform="translate(448, 1179)"><rect class="basic label-container" style="" x="-130" y="-27" width="260" height="54"></rect><g class="label" style="" transform="translate(-86, -18)"><rect></rect><foreignObject width="260" height="36"><div style="display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 260px; text-align: center;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel"><p class="globe">velut website</p></span></div></foreignObject></g></g></g></g></g></svg>

</div>

(Key: 📄&nbsp;file on my computer,📜&nbsp;JavaScript script, 🗄️&nbsp;database collection, 🌍&nbsp;website.)

Everything between the Json of source lemmata data and the MongoDB collections is handled by the [Data Updater](#the-data-updater).

</figure>
</details>

<details>
<summary>Explanation of diagram</summary>

The Json of source lemmata data is read by the Inflector, which generates a Json summary of Inflector work, which is imported into the `summary` MongoDB collection. The Inflector also generates a Json array of lemmata with their forms, which is imported into the `lemmata` MongoDB collection and is read by the Lemmata Collator. The Lemmata Collator generates a simple list of words with their lemmata & enclitic, which is read by the Word Data Generator to generate a Json array of word data, which is imported into the `words` MongoDB collection. The three MongoDB collections are read by the velut website.

</details>

(Note that the “summary” of Inflector work was only useful while I’m moving to the new architecture, since it’s used by the de-Excellation page that displays my progress with that.
If I delete that page, as I intend to do, I can get rid of that branch of the diagram and go back to having only two MongoDB collections.
I’m not even updating the summary anymore.)

## Evaluation

The de-Excellation of velut is one of my greatest accomplishments ever.
I made a detailed plan — anticipating that it would take years to execute — and followed it to great success.

With Excel, development of velut was very slow, limited in the number of word forms I could add, and incapable of delivering features such as inflection-tables.
Sometimes I lost data when the program crashed.

The migration to Json files and JavaScript scripts (and the Batch file that runs the scripts) has made editing the data much easier and has enabled velut to have complete inflection-tables.
Tasks that should be automated have been automated, while allowing a human (me) to oversee the things a human should oversee.
I can review output and adjust the source data (or indeed, the scripts’ code) as needed.

I’m using web development tools I’m familiar with, such as JavaScript and Git.
Perhaps the scripts would be quicker if they were in Python, or Rust, or C++.
But for me, for this project, knowing the language well is more important than making the code run extremely fast.
The speed of execution in Node is still a _huge_ improvement over Excel.

(But come to think of it, might a different JavaScript runtime be faster?
It probably wouldn’t be hard to adapt the code for Deno, or Bun.)

Arguably the worst thing about my code (aside from it being JavaScript), is how long the script files are.
The Lemmata Collator has [178 lines of code](https://github.com/DuncanRitchie/velut-lemmata-collator/blob/main/collator.js), the Word Data Generator has [1,247 lines of code](https://github.com/DuncanRitchie/velut-word-data-generator/blob/main/generator.js), and the Inflector has a whopping [5,327 lines of code](https://github.com/DuncanRitchie/velut-inflector/blob/main/inflector.js).
Perhaps a different developer would split the scripts up more and would have a nice way of ensuring the code still runs as it should.
For me, it’s nice to _not_ think about build stages and bundlers!
(What if the bundler fails?)

My new code is all on GitHub, so other devs might understand what I’m doing.
Admittedly the repo for the Data Updater is not publicly visible, since it contains my database credentials.
I should be able to extract the credentials to a secret file and publish the Data Updater without the credentials.
But this blogpost includes [the Data Updater](#the-data-updater) above, so the script can be read there.
It’s wonderful to be able to put so much of my code (and explanation of my code) online, especially without sharing the entire Excel file.

Documentation is easier to write and read — instead of adding notes to myself in Excel, I can write comments in the JavaScript, readme files in Git repos, and indeed lengthy blog articles!

I feel tired.

But energized to put more vocabulary into the dictionary!

<style>
	.no-break {
		/* Don’t break the line on hyphens. */
		white-space: nowrap;
	}

	.checklist {
		list-style: none;
		padding-left: 0;
		text-indent: 1.5em hanging;
	}

	details:has(.mermaid) {
		margin-bottom: 1rem
	}

	figure .mermaid ~ p {
		text-align: left;
		padding-inline: 0.5rem;
	}

	.mermaid {
		width: unset;
	}

	.mermaid .file::before {
		content: "📄 ";
	}

	.mermaid .scroll::before {
		content: "📜 ";
	}

	.mermaid .database::before {
		content: "🗄️ ";
	}

	.mermaid .globe::before {
		content: "🌍 ";
	}
</style>
